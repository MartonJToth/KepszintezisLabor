{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartonJToth/KepszintezisLabor/blob/master/KepszintezisLabor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WoxccpdJwUEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install ellenőrzés"
      ]
    },
    {
      "metadata": {
        "id": "je6gC96bqJU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision \n",
        "!pip install matplotlib\n",
        "!pip3 install Pillow==4.2.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fozPBFJEr2gQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urGPgctjwlnk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Adatbázis letöltés"
      ]
    },
    {
      "metadata": {
        "id": "3E29uW4UwowH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://cg.iit.bme.hu/~tmarton/deeplearning/DehazeImages.zip\n",
        "!unzip -qq DehazeImages.zip\n",
        "!rm DehazeImages.zip\n",
        "!mkdir Results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6d4IERYv92yF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "__1tblq094dC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "import PIL\n",
        "from PIL import Image, ImageCms\n",
        "\n",
        "\n",
        "class DehazeDataset(Dataset):\n",
        "\n",
        "    train_input = []\n",
        "    train_results = []\n",
        "\n",
        "    validation_input = []\n",
        "    validation_results = []\n",
        "\n",
        "    trainNum = 0\n",
        "    valNum = 0\n",
        "    width = 0\n",
        "    height = 0\n",
        "\n",
        "    def __init__(self, path, type='training', percentage='0.8', transform=None):\n",
        "\n",
        "        self.sampleNum = 0\n",
        "        self.width = 0\n",
        "        self.height = 0\n",
        "        self.channels = 3\n",
        "        self.type = type\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        self.srgb_profile = ImageCms.createProfile(\"sRGB\")\n",
        "        self.lab_profile = ImageCms.createProfile(\"LAB\")\n",
        "\n",
        "        self.rgb2lab_transform = ImageCms.buildTransformFromOpenProfiles(self.srgb_profile, self.lab_profile, \"RGB\", \"LAB\")\n",
        "\n",
        "        if len(DehazeDataset.train_input) == 0:\n",
        "\n",
        "            numFiles = len([name for name in os.listdir(path) if os.path.isfile(os.path.join(path, name))])\n",
        "\n",
        "            first = True\n",
        "\n",
        "            for i in range(numFiles // 2):\n",
        "\n",
        "                istr = str(i)\n",
        "\n",
        "                while len(istr) < 5:\n",
        "                    istr = '0' + istr\n",
        "\n",
        "                inputPath = os.path.join(path, 'hazy_' + istr + '.png')\n",
        "                resultPath = os.path.join(path, 'normal_' + istr + '.png')\n",
        "\n",
        "                if first:\n",
        "                    first = False\n",
        "                    im = imageio.imread(uri=inputPath)\n",
        "                    DehazeDataset.width = im.shape[0]\n",
        "                    DehazeDataset.height = im.shape[1]\n",
        "\n",
        "                if random.random() <= percentage:\n",
        "\n",
        "                    DehazeDataset.train_input.append(inputPath)\n",
        "                    DehazeDataset.train_results.append(resultPath)\n",
        "\n",
        "                else:\n",
        "\n",
        "                    DehazeDataset.validation_input.append(inputPath)\n",
        "                    DehazeDataset.validation_results.append(resultPath)\n",
        "\n",
        "        self.width = DehazeDataset.width\n",
        "        self.height = DehazeDataset.height\n",
        "\n",
        "        if type == 'training':\n",
        "            self.sampleNum = len(DehazeDataset.train_input)\n",
        "        else:\n",
        "            self.sampleNum = len(DehazeDataset.validation_input)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.sampleNum\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = np.zeros((self.width, self.height, self.channels), dtype='f')\n",
        "        y = np.zeros((self.width, self.height, self.channels), dtype='f')\n",
        "\n",
        "        if self.type == 'training':\n",
        "\n",
        "            inputImage = Image.open(DehazeDataset.train_input[idx])\n",
        "            resultImage = Image.open(DehazeDataset.train_results[idx])\n",
        "\n",
        "        else:\n",
        "\n",
        "            inputImage = Image.open(DehazeDataset.validation_input[idx])\n",
        "            resultImage = Image.open(DehazeDataset.validation_results[idx])\n",
        "\n",
        "        inputImage = inputImage.resize((self.width, self.height), PIL.Image.ANTIALIAS)\n",
        "        inputImage = inputImage.convert('RGB')\n",
        "        resultImage = resultImage.resize((self.width, self.height), PIL.Image.ANTIALIAS)\n",
        "        resultImage = resultImage.convert('RGB')\n",
        "\n",
        "        inputImage = np.array(inputImage)\n",
        "        inputImage = np.true_divide(inputImage, 255)\n",
        "        resultImage = np.array(resultImage)\n",
        "        resultImage = np.true_divide(resultImage, 255)\n",
        "\n",
        "        x[:, :, :] = inputImage\n",
        "        y[:, :, :] = resultImage\n",
        "\n",
        "        x = np.transpose(x, (2, 1, 0))\n",
        "        y = np.transpose(y, (2, 1, 0))\n",
        "\n",
        "        sample = {'input': x, 'output': y}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "      \n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hAXoJ-pO-FKM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transform"
      ]
    },
    {
      "metadata": {
        "id": "9chdFdJ6-ETy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ToTensor(object):\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        input, output = sample['input'], sample['output']\n",
        "\n",
        "        return {'input': torch.from_numpy(input),\n",
        "                'output': torch.from_numpy(output)}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6johMc8-o3p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model"
      ]
    },
    {
      "metadata": {
        "id": "zcp7ZP_l-qDh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyModelScript(torch.jit.ScriptModule):\n",
        "    def __init__(self):\n",
        "        super(MyModelScript, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=5, padding=2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=6, out_channels=3, kernel_size=7, padding=3)\n",
        "        self.conv5 = nn.Conv2d(in_channels=12, out_channels=3, kernel_size=3, padding=1)\n",
        "        self.b = 1\n",
        "\n",
        "    @torch.jit.script_method\n",
        "    def forward(self, x):\n",
        "        x1 = F.relu(self.conv1(x))\n",
        "        x2 = F.relu(self.conv2(x1))\n",
        "        cat1 = torch.cat((x1, x2), 1)\n",
        "        x3 = F.relu(self.conv3(cat1))\n",
        "        cat2 = torch.cat((x2, x3),1)\n",
        "        x4 = F.relu(self.conv4(cat2))\n",
        "        cat3 = torch.cat((x1, x2, x3, x4),1)\n",
        "        k = F.relu(self.conv5(cat3))\n",
        "\n",
        "        output = k * x - k + 1\n",
        "        return F.relu(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezuLFVGP_Rmk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training"
      ]
    },
    {
      "metadata": {
        "id": "NyTTbCVD_S0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "def train(epoch, net, trainLoader, optimizer, criterion, haveCuda):\n",
        "\n",
        "  # variables for loss\n",
        "  running_loss = 0.0\n",
        "\n",
        "  # set the network to train (for batchnorm and dropout)\n",
        "  net.train()\n",
        "  \n",
        "  # Create progress bar\n",
        "  bar = display(progress(0, len(trainLoader)), display_id=True)\n",
        "\n",
        "  # Epoch loop\n",
        "  for i, data in enumerate(trainLoader, 0):\n",
        "\n",
        "\n",
        "    input, output = data['input'], data['output']\n",
        "\n",
        "    # Convert to cuda conditionally\n",
        "    if haveCuda:\n",
        "        input, output = input.cuda(), output.cuda()\n",
        "\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    result = net(input)\n",
        "\n",
        "    loss = criterion(result, output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # compute statistics\n",
        "    running_loss += loss.item()\n",
        "    \n",
        "    # Update progress bar\n",
        "    bar.update(progress(i+1, len(trainLoader)))\n",
        "\n",
        "  # print and plot statistics\n",
        "  tr_loss = running_loss / len(trainLoader)\n",
        "  print(\"Train epoch %d loss: %.3f\" % (epoch + 1, tr_loss))\n",
        "\n",
        "  return tr_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-TwCUNZj_d7G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "WuFBQyvOMuSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure, imshow, axis\n",
        "\n",
        "def displayImages(images):\n",
        "  \n",
        "  fig = figure(figsize=(20, 10), dpi=80)\n",
        "  number_of_files = len(images)\n",
        "  for i in range(len(images)):\n",
        "      a=fig.add_subplot(1,number_of_files,i+1)\n",
        "      image = images[i]\n",
        "      imshow(image,cmap='Greys_r')\n",
        "      axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "og5FP_IE_fJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import scipy\n",
        "import scipy.misc\n",
        "from PIL import Image, ImageCms\n",
        "from IPython.display import display\n",
        "\n",
        "def eval(epoch, net, valloader, criterion, haveCuda):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  net.eval()  \n",
        "  \n",
        "  images = []\n",
        "\n",
        "  for i, data in enumerate(valloader, 0):\n",
        "\n",
        "    input, output = data['input'], data['output']\n",
        "\n",
        "    nx = input[0, :, :, :].detach().numpy()\n",
        "    nx = np.transpose(nx, (2, 1, 0))\n",
        "\n",
        "    image = np.zeros((nx.shape[0] * 2, nx.shape[1], nx.shape[2]))\n",
        "    \n",
        "    image[0:nx.shape[0], :, :] = nx\n",
        "\n",
        "    if haveCuda:\n",
        "        input, output = input.cuda(), output.cuda()\n",
        "\n",
        "    result = net(input)\n",
        "    loss = criterion(result, output)\n",
        "\n",
        "    nx = result[0, :, :, :].detach()\n",
        "    nx = nx.cpu().numpy()\n",
        "    nx = np.transpose(nx, (2, 1, 0))\n",
        "\n",
        "    image[nx.shape[0]:nx.shape[0]*2, :, :] = nx\n",
        "    \n",
        "    im = Image.fromarray(np.uint8(image * 255))\n",
        "    \n",
        "    if(len(images) < 10):\n",
        "      images.append(im)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  tr_loss = running_loss / len(valloader)\n",
        "  print(\"Validation epoch %d loss: %.3f\" % (epoch + 1, tr_loss))\n",
        "  \n",
        "  displayImages(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YZW4TGD458uP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Custom loss"
      ]
    },
    {
      "metadata": {
        "id": "Y1PBoZ1Y6C6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from math import exp\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel):\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
        "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
        "    return window\n",
        "\n",
        "\n",
        "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
        "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
        "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
        "\n",
        "    mu1_sq = mu1.pow(2)\n",
        "    mu2_sq = mu2.pow(2)\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
        "\n",
        "    C1 = 0.01 ** 2\n",
        "    C2 = 0.03 ** 2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "\n",
        "    if size_average:\n",
        "        return ssim_map.mean()\n",
        "    else:\n",
        "        return ssim_map.mean(1).mean(1).mean(1)\n",
        "\n",
        "\n",
        "class SSIM(torch.nn.Module):\n",
        "    def __init__(self, window_size=11, size_average=True):\n",
        "        super(SSIM, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.size_average = size_average\n",
        "        self.channel = 1\n",
        "        self.window = create_window(window_size, self.channel)\n",
        "\n",
        "    def forward(self, img1, img2):\n",
        "        (_, channel, _, _) = img1.size()\n",
        "\n",
        "        if channel == self.channel and self.window.data.type() == img1.data.type():\n",
        "            window = self.window\n",
        "        else:\n",
        "            window = create_window(self.window_size, channel)\n",
        "\n",
        "            if img1.is_cuda:\n",
        "                window = window.cuda(img1.get_device())\n",
        "            window = window.type_as(img1)\n",
        "\n",
        "            self.window = window\n",
        "            self.channel = channel\n",
        "\n",
        "        return _ssim(img1, img2, window, self.window_size, channel, self.size_average)\n",
        "\n",
        "\n",
        "def ssim(img1, img2, window_size=11, size_average=True):\n",
        "    (_, channel, _, _) = img1.size()\n",
        "    window = create_window(window_size, channel)\n",
        "\n",
        "    if img1.is_cuda:\n",
        "        window = window.cuda(img1.get_device())\n",
        "    window = window.type_as(img1)\n",
        "\n",
        "\n",
        "    return _ssim(img1, img2, window, window_size, channel, size_average)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cQRv_SdQ6s5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, cuda):\n",
        "        super(MyLoss, self).__init__()\n",
        "\n",
        "        a = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])\n",
        "        self.conv1 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.conv1.weight = nn.Parameter(torch.from_numpy(a).float().unsqueeze(0).unsqueeze(0))\n",
        "\n",
        "        b = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])\n",
        "        self.conv2 = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.conv2.weight = nn.Parameter(torch.from_numpy(b).float().unsqueeze(0).unsqueeze(0))\n",
        "\n",
        "        self.ssim_loss = ssim.SSIM()\n",
        "\n",
        "        self.cuda = cuda\n",
        "        if cuda:\n",
        "            self.conv1.cuda()\n",
        "            self.conv2.cuda()\n",
        "\n",
        "    def getLuminance(self, x):\n",
        "\n",
        "        L = torch.autograd.Variable(torch.zeros([x.size()[0], 1, x.size()[2], x.size()[3]]), requires_grad=False)\n",
        "\n",
        "        if self.cuda:\n",
        "            L = L.cuda()\n",
        "\n",
        "        L[:, 0, :, :] = 0.2126 * x[:, 0, :, :] + 0.7152 * x[:, 1, :, :] + 0.0722 * x[:, 2, :, :]\n",
        "\n",
        "        return L\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        Lx = self.getLuminance(x)\n",
        "        Ly = self.getLuminance(y)\n",
        "\n",
        "        #dLxx = self.conv1(Lx)\n",
        "        #dLxy = self.conv2(Lx)\n",
        "\n",
        "        #dLyx = self.conv1(Ly)\n",
        "        #dLyy = self.conv2(Ly)\n",
        "\n",
        "        diff = x - y\n",
        "        diff = torch.sum(diff.abs()) / x.numel()\n",
        "\n",
        "        loss = diff \n",
        "        \n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "78UAof1mAtNa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Main"
      ]
    },
    {
      "metadata": {
        "id": "PCW_DqceAsjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "haveCuda = torch.cuda.is_available()\n",
        "\n",
        "path = './DehazeImages'\n",
        "seed = 1\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if haveCuda:\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "tt = ToTensor()\n",
        "trainingDS = DehazeDataset(path=path, type='training', percentage=0.8, transform=tt)\n",
        "validationDS = DehazeDataset(path=path, type='validation', transform=tt)\n",
        "\n",
        "trainingDL = DataLoader(trainingDS, batch_size=16, shuffle=True, num_workers=4)\n",
        "validationDL = DataLoader(validationDS, batch_size=16, shuffle=True, num_workers=4)\n",
        "\n",
        "nn = MyModelScript()\n",
        "\n",
        "if haveCuda:\n",
        "  nn = nn.cuda()\n",
        "\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(nn.parameters(), lr=1e-4, weight_decay=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=53760, gamma=0.5)\n",
        "\n",
        "numEpoch = 5\n",
        "\n",
        "for i in range(numEpoch):\n",
        "\n",
        "  train(i, nn, trainingDL, optimizer, criterion, haveCuda)\n",
        "  eval(i, nn, validationDL, criterion, haveCuda)\n",
        "\n",
        "nn.cpu()\n",
        "nn.save('cuda_trined_model.pt')\n",
        "\n",
        "print('Model saved')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}